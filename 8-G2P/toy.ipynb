{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import IPython.display\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if no preprocessing done then run the following\n",
    "words = words[words.word.notnull()]\n",
    "words = words[~words.phonem.str.contains('#')]\n",
    "def onehotEncoder(row):\n",
    "    res = []\n",
    "    len_word = len(row.word)\n",
    "    len_phonem = len(row.phonem.split())\n",
    "    len_total = len_word+len_phonem+1\n",
    "    word = row.word\n",
    "    word += \"%\" # Terminating character\n",
    "    word += ''.join(['?' for i in range(len_phonem)]) # filling the remaining with ? chars\n",
    "    res = np.array(letters_encoder.transform([[l] for l in word]).toarray()) # encoding the string\n",
    "    phonem = ['?' for i in range(len_word+1)] + row.phonem.split()\n",
    "    phonem_enc = phonem_encoder.transform([[l] for l in phonem]).toarray()\n",
    "    return res, phonem_enc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = words.apply(onehotEncoder, axis = 1,result_type='expand')\n",
    "\n",
    "encoded = encoded.rename(columns={0:'word_encoded', 1:'phonem_encoded'})\n",
    "\n",
    "encoded.iloc[0].word_encoded\n",
    "\n",
    "encoded.to_json('data.json.bz2', compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_encoded</th>\n",
       "      <th>phonem_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        word_encoded  \\\n",
       "0  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "3  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                      phonem_encoded  \n",
       "0  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "1  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "2  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "3  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  "
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_json('data.json.gz', compression='gzip')\n",
    "X = words.word_encoded.to_numpy()\n",
    "y = words.phonem_encoded.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones = pd.read_csv('phonems.csv')['Phonems'].to_numpy()\n",
    "words = pd.read_csv('words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>phonem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'bout</td>\n",
       "      <td>B AW T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'cause</td>\n",
       "      <td>K AH Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'course</td>\n",
       "      <td>K AO R S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'cuse</td>\n",
       "      <td>K Y UW Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'em</td>\n",
       "      <td>AH M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125992</th>\n",
       "      <td>zysk</td>\n",
       "      <td>Z AY S K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125993</th>\n",
       "      <td>zyskowski</td>\n",
       "      <td>Z IH S K AO F S K IY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125994</th>\n",
       "      <td>zyuganov</td>\n",
       "      <td>Z Y UW G AA N AA V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125995</th>\n",
       "      <td>zyuganov's</td>\n",
       "      <td>Z Y UW G AA N AA V Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125996</th>\n",
       "      <td>zywicki</td>\n",
       "      <td>Z IH W IH K IY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125997 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word                phonem\n",
       "0            'bout                B AW T\n",
       "1           'cause                K AH Z\n",
       "2          'course              K AO R S\n",
       "3            'cuse              K Y UW Z\n",
       "4              'em                  AH M\n",
       "...            ...                   ...\n",
       "125992        zysk              Z AY S K\n",
       "125993   zyskowski  Z IH S K AO F S K IY\n",
       "125994    zyuganov    Z Y UW G AA N AA V\n",
       "125995  zyuganov's  Z Y UW G AA N AA V Z\n",
       "125996     zywicki        Z IH W IH K IY\n",
       "\n",
       "[125997 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = [[letter] for letter in string.ascii_lowercase+\".'-?%\"]\n",
    "phonem = [[str(ph)] for ph in np.append(phones, '?')]\n",
    "\n",
    "letters_encoder = OneHotEncoder()\n",
    "phonem_encoder = OneHotEncoder()\n",
    "\n",
    "letters_encoder.fit(letters)\n",
    "phonem_encoder.fit(phonem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 40)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = letters_encoder.categories_[0].shape[0]\n",
    "output_shape = phonem_encoder.categories_[0].shape[0]\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(None, input_shape))\n",
    "lstm_512 = LSTM(512, return_sequences=True)(input_layer)\n",
    "dropout_1 = Dropout(0.4)(lstm_512)\n",
    "blstm_512 = Bidirectional(LSTM(512, return_sequences=True))(input_layer)\n",
    "dropout_2 = Dropout(0.4)(blstm_512)\n",
    "lstm_128 = LSTM(128, return_sequences=True)(keras.layers.concatenate([dropout_1, dropout_2]))\n",
    "dropout_3 = Dropout(0.3)(lstm_128)\n",
    "output = Dense(output_shape, activation='softmax')(dropout_3)\n",
    "model = Model(input_layer, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 31)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, None, 512)    1114112     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, None, 1024)   2228224     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 512)    0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 1024)   0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 1536)   0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, None, 128)    852480      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 128)    0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 40)     5160        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,199,976\n",
      "Trainable params: 4,199,976\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"saved_weights/weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = set()\n",
    "for i in X_train:\n",
    "    size.add(np.asarray(i).shape)\n",
    "size = list(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "119/119 [==============================] - 84s 707ms/step - loss: 0.2944 - accuracy: 0.9187 - val_loss: 0.1779 - val_accuracy: 0.9424\n",
      "Epoch 2/20\n",
      "119/119 [==============================] - 85s 718ms/step - loss: 0.1670 - accuracy: 0.9482 - val_loss: 0.1690 - val_accuracy: 0.9465\n",
      "Epoch 3/20\n",
      "119/119 [==============================] - 85s 713ms/step - loss: 0.1230 - accuracy: 0.9604 - val_loss: 0.1709 - val_accuracy: 0.9479\n",
      "Epoch 4/20\n",
      "119/119 [==============================] - 84s 707ms/step - loss: 0.1019 - accuracy: 0.9668 - val_loss: 0.1678 - val_accuracy: 0.9503\n",
      "Epoch 5/20\n",
      "  4/119 [>.............................] - ETA: 58s - loss: 0.0892 - accuracy: 0.9715"
     ]
    }
   ],
   "source": [
    "for j in size:\n",
    "    new_X_train = []\n",
    "    new_Y_train = []\n",
    "    new_X_valid = []\n",
    "    new_Y_valid = []\n",
    "    for i in range(len(X_train)):\n",
    "        if len(X_train[i]) == j[0]:\n",
    "            new_X_train.append(np.asarray(X_train[i]))\n",
    "            new_Y_train.append(np.asarray(y_train[i]))\n",
    "        try:\n",
    "            if len(X_test[i]) == j[0]:\n",
    "                new_X_valid.append(X_test[i])\n",
    "                new_Y_valid.append(y_test[i])\n",
    "        except:\n",
    "            continue\n",
    "    if len(new_X_train)> 32:\n",
    "        IPython.display.clear_output(True) \n",
    "        model.fit(np.asarray(new_X_train), np.asarray(new_Y_train), epochs=20, \n",
    "                  batch_size=32, callbacks=callbacks_list, validation_data=\n",
    "                 (np.asarray(new_X_valid), np.asarray(new_Y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"barn%????\"\n",
    "p = model.predict(np.asarray([letters_encoder.transform([[i] for i in s]).toarray()]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B AA R N'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([phonem_encoder.categories_[0][np.argmax(i)] for i in p]).replace('? ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
